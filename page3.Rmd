---
title: "데이터 과학을 위한 파이썬"
subtitle: "03. 데이터 다루기: numpy & pandas"
author: "민형규, 간정현, DataScience Lab"
output: 
  rmdformats::readthedown:
    css: "assets/css/typo.css"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(tidyverse)
use_python("C://User/Administrator/Anaconda3/python3")
```

- [00. 데이터 과학을 위한 파이썬](https://yonseidslab.github.io/pyfords/)
- [01. 자료형과 연산자](https://yonseidslab.github.io/pyfords/page1)
- [02. 제어문, 클래스, 패키지](https://yonseidslab.github.io/pyfords/page2)
- [03. 데이터 다루기: numpy & pandas](https://yonseidslab.github.io/pyfords/page3)
- [04. 시각화: matplotlib, seaborn](https://yonseidslab.github.io/pyfords/page4)

# Intro

`numpy`는 과학 계산을 위한 파이썬 패키지이며, 다차원 자료구조 `ndarray`를 통해 효율적인 벡터/행렬 계산 기능을 제공합니다. `pandas`는 넘파이를 기반으로 데이터 사이언스에 필요한 자료구조 및 데이터 핸들링 기능들을 제공합니다. 대표적으로 1차원 자료구조인 `Series`와 2차원 자료구조인 `DataFrame`을 지원합니다. 우리는 넘파이보다는 판다스를 집중적으로 다룰 것이지만, 판다스의 자료구조들이 결국은 넘파이의 어레이를 기반으로 만들어지므로 넘파이에 대한 최소한의 이해는 필요합니다.

# 1. Numpy 튜토리얼

시작하기 전에, `numpy` 패키지를 `np`라는 이름으로 불러오겠습니다.

```{python eval=F}
>>> import numpy as np
```

## 1.1. ndarray

넘파이의 핵심은 `ndarray` 클래스입니다. 어레이는 지금까지 다룬 리스트와 유사하지만 더욱 강력한 성능과 기능을 제공합니다.  `np.array()` 함수 안에 리스트를 집어넣으면 어레이를 만들 수 있습니다.

```{python eval=F}
>>> a = [1,2,3]
>>> np.array(a)
array([1, 2, 3])
>>> b = [4,5]
>>> np.array(b)
array([4,5])
>>> np.array([1,2,3,4,5])
array([1,2,3,4,5])
```

## 1.2. 어레이와 자료형

어레이가 포함하는 요소들은 모두 같은 자료형을 가져야만 하며, 어레이를 만들 때 `dtype` 매개변수를 활용하여 자료형을 직접 지정할 수 있습니다. 데이터 타입을 지정하지 않으면 넘파이가 자동으로 데이터 타입을 판단합니다. 만들어진 어레이의 데이터 타입을 확인할 때는 `dtype` 속성을 활용합니다. 

```{python eval=F}
>>> a = np.array([1,2,3], dtype="int8") # 내부 자료가 차지하는 메모리 직접 제한 가능
>>> a.dtype # dtype 속성을 통해 자료형에 접근 가능
dtype('int8')
```

어레이의 자료형을 변환할 때는 `astype` 메소드를 활용합니다. 괄호 안에 원하는 자료형을 적어주면 어레이를 해당 자료형으로 변환한 결과가 출력됩니다. 역시 어레이를 직접적으로 변화시키는 메소드가 아니기 때문에 결과를 저장하려면 다시 할당을 해주어야 합니다. 

<div class="row">
  <div class="col-md-6">
```{python eval=F}
>>> a = np.array([1,2,3])
>>> a.astype('str')
array(['1', '2', '3'], dtype='<U4')
```
 </div>
 <div class="col-md-6">
```{python eval=F}
>>> a = np.array([1,2,3])
>>> a.astype('float16')
array([1., 2., 3.], dtype=float16)
```
  </div>
</div>


## 1.3. n차원 어레이와 shape

![이미지 출처: Tensors, The Building Block For Deep Learning](http://www.curiousinspiration.com/media/section-848.png)

**넘파이의 1차원 어레이는 하나의 행 벡터처럼 생각할 수 있습니다.** 따라서 여러 개의 1차원 어레이를 결합하면, 하나의 행렬을 만들 수 있을 것입니다. 예를 들어 $\vec{u} = (1,2,3)$ 이라는 벡터와 $\vec{v} = (4,5,6)$이라는 벡터를 두 개의 행으로 갖는 $2 \times 3$ 크기의 행렬 $A$를 넘파이로 구현해보겠습니다.

$$A = \begin{pmatrix}
 \vec{u} \\
 \vec{v} \\
 \end{pmatrix} = 
 \begin{pmatrix}
 1 & 2 & 3 \\
 4 & 5 & 6 \\
 \end{pmatrix}
 $$
<div class="row">
  <div class="col-md-6">
```{python eval=F}
>>> u = np.array([1,2,3])
>>> v = np.array([4,5,6])
>>> A = np.array([u,v])
>>> A
array([[1, 2, 3],
       [4, 5, 6]])
>>> A.shape
(2,3)
```
  </div>
  <div class="col-md-6">
```{python eval=F}
>>> A = np.array([[1,2,3],[4,5,6])
>>> A
array([[1, 2, 3],
       [4, 5, 6]])
>>> A.shape
(2,3)

```
  </div>
</div>

위 예시 코드에서 `u`와 `v`는 각각 $(1,2,3)$, $(4,5,6)$ 을 표현하는 어레이입니다. 두 개의 어레이를 다시 `np.array` 함수로 묶은 것이 `A`입니다. `shape`은 어레이의 모양을 나타내는 속성입니다. 즉 행렬로 따지면 $m \times n$ 의 사이즈를 나타냅니다. 오른쪽 코드처럼 리스트로 행렬구조를 표현하여 즉시 어레이를 만들어줄 수도 있습니다.

차수가 서로 다른 벡터들을 가지고 행렬을 만들 수 없듯이, 길이가 서로 다른 1차원 어레이를 가지고도 2차원 어레이를 만들 수 없습니다. 길이가 서로 다른 1차원 어레이들을 쌓으면 결과는 1차원 어레이들을 요소로 갖는 1차원 어레이가 됩니다.

```{python eval=F}
>>> u = np.array([1,2,3])
>>> v = np.array([4,5])
>>> A = np.array([u,v])
>>> A
array([list([1, 2, 3]), list([4, 5])], dtype=object)
>>> A.shape
(2,)
```

넘파이 배열은 3차원 이상으로도 확장될 수 있습니다. 3차원 이상의 배열로 확장할 때에도 마찬가지로 요소들의 `shape`이 일치해야 합니다. 차원이 늘어나면, `shape`의 앞쪽으로 확장된 차수가 추가됩니다.

$$A = 
 \begin{pmatrix}
 1 & 2 & 3 \\
 3 & 4 & 5 \\
 \end{pmatrix}, \space
 B = 
 \begin{pmatrix}
 5 & 6 & 7 \\
 7 & 8 & 9 \\
 \end{pmatrix}
$$

```{python eval=F}
>>> A = np.array([[1,2,3],[3,4,5]])
>>> A.shape
(2,3)
>>> B = np.array([[5,6,7],[7,8,9]])
>>> B.shape
(2,3)
>>> C = np.array([A,B])
>>> C
array([[[1, 2, 3],
        [3, 4, 5]],

       [[5, 6, 7],
        [7, 8, 9]]])

>>> >>> C.shape
(2, 2, 3)
```

위 예시 코드에서 `A`와 `B`는 각각 $2 \times 3$ 행렬입니다. `C`는 `A` 와 `B`를 쌓아서 만든 $2 \times 2 \times 3$ 텐서입니다. 즉 2개의 행렬 안에 각각 2개의 벡터가 들어있고, 각각의 벡터 안에 3개의 스칼라가 들어있는 모양입니다.

## 1.4. 어레이 인덱싱

어레이의 인덱싱 역시 대괄호`[]`와 콜론`:`을 사용합니다. 어레이 인덱싱에서 주의할 점은 인덱싱 문법이 어레이의 `shape`에 대응한다는 점입니다. 즉 `(2,3,4)`와 같은 `shape`을 갖는 어레이에서 하나의 스칼라를 인덱싱하는 경우, `[0,0,0]` 부터 `[1,2,3]` 의 인덱스 범위가 존재하게 됩니다. 여기에서는 2차원 어레이의 인덱싱까지만 다룹니다.

### 1차원 어레이

1차원 어레이의 인덱싱은 파이썬 리스트 인덱싱과 크게 다를 것 없습니다.

```{python eval=F}
>>> a = np.array([1,2,3])
>>> a[0]
1
>>> a[:2]
array([1, 2])
```

### 2차원 어레이

행렬 $A$ 에 대응하는 2차원 어레이 `A`를 아래와 같이 구현해보겠습니다.

$$A = 
 \begin{pmatrix}
 1 & 2 & 3 \\
 4 & 5 & 6 \\
 \end{pmatrix}
$$

```{python eval=F}
>>> A = np.array([[1,2,3],[4,5,6]])
>>> A
array([[1, 2, 3],
       [4, 5, 6]])
```

2차원 어레이에서 하나의 스칼라를 인덱싱할 때에는 `A[행인덱스,열인덱스]`과 같이 쓰면 됩니다. 즉 2행 1열의 요소를 인덱싱히려면 다음과 같이 쓰면 됩니다. 파이썬의 인덱스는 `0`부터 시작하기 때문에 `[2,1]`이 아니라 `[1,0]`이 됩니다.

```{python eval=F}
>>> A[1,0]
4
```

이번에는 슬라이싱을 적용해서 세 번째 열 전체를 가져와보겠습니다. 전체 행에 대해서 세 번째 열의 요소만들 가져오므로 구간은 `[:,2]`와 같이 표현합니다.

```{python eval=F}
>>> A[:,2]
array([3, 6])
```

:::warning
**예제 1.1. 어레이 A에서 4와 5를 인덱싱해보세요.**

```{python eval=F}
>>> A = np.array([[1,2,3],[4,5,6]])
```

**풀이**

두 번째 행 벡터에서 두 번째 요소까지를 가져오면 되는 문제입니다. 따라서 구간은 [1,:2]가 됩니다.

```{python eval=F}
>>> A[1,:2]
array([4, 5])
```
:::

## 1.5. 어레이 연산

### 같은 쉐입의 연산

어레이의 쉐입이 같을 때, `+`, `-`, `*`, `-`, `**` 등 기본 연산은 같은 위치의 원소들끼리 연산한 결과를 반환합니다.

```{python eval=F}
>>> u = np.array([1,2,3])
>>> v = np.array([4,5,6])
```

<div class="row">
  <div class="col-md-6">
**덧셈**
```{python eval=F}
>>> u + v
array([5, 7, 9])
```
  </div>
  <div class="col-md-6">
**뺄셈**
```{python eval=F}
>>> u - v
array([-3, -3, -3])
```
  </div>
</div>

<div class="row">
  <div class="col-md-6">
**곱셈**
```{python eval=F}
>>> u * v
array([ 4, 10, 18])
```
  </div>
  <div class="col-md-6">
**나눗셈**
```{python eval=F}
>>> u / v
array([0.25, 0.4 , 0.5 ])
```
  </div>
</div>


### 다른 `shape`의 연산: 브로드캐스팅

![출처: numpy.ndarray객체의 브로드캐스팅(broadcasting)](http://2.bp.blogspot.com/-FjpwaGpHonQ/VTlvgBlMY_I/AAAAAAAAANk/vfFsuGjmlmk/s1600/numpy_broadcasting.png)

넘파이는 서로 다른 쉐입의 자료들 간에도 연산을 지원합니다. 물론 모든 어레이들이 서로 호환되는 것은 아닙니다. 2차원까지의 어레이에 한정하여 말하면 다음과 같은 경우에 브로드캐스팅이 가능합니다. 여기에서는 스칼라 연산의 결과만을 확인해보겠습니다.

- 스칼라와 벡터, 스칼라와 행렬 간의 연산
- $m \times n$ 행렬과 $m \times 1$ 벡터 간의 연산
- $m \times n$ 행렬과 $1 \times n$ 벡터 간의 연산
 - $m \times 1$ 벡터와 $1 \times n$ 벡터 간의 연산

<div class="row">
  <div class="col-md-6">
**덧셈**

```{python eval=F}
>>> a = np.array([1,2,3])
>>> a + 3
array([4, 5, 6])
```
  </div>
  <div class="col-md-6">
**뺄셈**
```{python eval=F}
>>> a = np.array([1,2,3])
>>> a - 1
array([0, 1, 2])
```
  </div>
</div>

<div class="row">
  <div class="col-md-6">
**곱셈**

```{python eval=F}
>>> a = np.array([1,2,3])
>>> a * 3
array([3, 6, 9])
```
  </div>
  <div class="col-md-6">
**나눗셈**
```{python eval=F}
>>> a = np.array([1,2,3])
>>> a / 2
array([0.5, 1. , 1.5])
```
  </div>
</div>

## 1.6. 기타 함수와 메소드

### numpy 함수

- `np.dot` : 두 벡터의 내적을 계산
- `np.matmul` : 두 행렬의 곱을 계산
- `np.power` : 배열 내 요소들의 n승
- `np.sqrt` : 배열 내 요소들의 제곱근

### ndarray 메소드

- `ndarray.transpose` : 전치
- `ndarray.reshape` : shape 재배열

# 2. Pandas

시작하기 전에, `pandas`를 `pd`라는 별칭으로 불러오겠습니다.

```{python echo=F}
import numpy as np
import pandas as pd
```

```{python eval=F}
>>> import pandas as pd
```

## 2.1. 판다스의 자료형

판다스의 핵심은 1차원 자료형 클래스 `Series`, 2차원 자료형 클래스 `DataFrame`입니다. 시리즈와 데이터프레임은 각각 넘파이의 1차원 어레이, 2차원 어레이에 더욱 다양한 기능들을 추가하여 만들어졌습니다. **시리즈는 대부분의 경우 하나의 열, 변수, 피쳐를 나타내며, 여러 개의 시리즈들을 한데 묶은 것이 데이터프레임입니다.** 아래 그림은 `apples`, `oranges`라는 두 개의 컬럼이 하나의 데이터프레임을 이루는 모습입니다.

![출처: Python Pandas Tutorial: A Complete Introduction for Beginners](https://storage.googleapis.com/lds-media/images/series-and-dataframe.width-1200.png)

## 2.2. 시리즈

시리즈를 만들 때는 `pd.Series` 안에 리스트 혹은 넘파이 어레이를 넣어줍니다. 출력해보면 하나의 열처럼 세로로 값들이 떨어지는 것을 볼 수 있습니다. 시리즈가 하나의 컬럼이라는 것을 꼭 기억해주세요.

```{python eval=F}
>>> pd.Series([1,2,3,4,5])
0    1
1    2
2    3
3    4
4    5
dtype: int64
```

### apply

```{python eval=F}
>>> 시리즈.apply(함수) # lambda 함수와 조합해서 사용하는 경우가 많습니다
```

`apply` 메소드는 판다스 시리즈에서 꼭 짚고 넘어가야 할 부분입니다. 앞에서 다루었던 `map` 함수와 유사한 기능을 하는 메소드로, 시리즈의 각 요소들에 주어진 함수를 적용합니다. `for` 루프보다 빠르고 문법도 간결해서 많이 쓰이는 메소드입니다. 개인적으로 숫자 시리즈보다는 문자열 시리즈에서 유용하게 사용합니다.

```{python eval=F}
>>> mySeries = pd.Series(["서울 서대문구", "서울 중랑구", "서울 강남구"])
>>> mySeries.apply(lambda x: x.split(" ")[1])
0    서대문구
1     중랑구
2     강남구
dtype: object
```

위의 예시 코드는 "서울시 ~구" 형태로 이루어진 문자열 시리즈에서 구만을 뽑아내는 조작입니다. `lambda` 함수는 문자열을 공백을 기준으로 나누고, 반환된 리스트에서 `1`번 인덱스의 값을 반환하도록 되어 있습니다. 이 함수를 `apply` 메소드와 함께 활용하면, 함수를 시리즈의 각 요소에 적용한 결과를 얻을 수 있습니다.

:::warning
**예제 2.1. `apply` 메소드를 활용하여 `dateTime` 시리즈 각 날짜에 해당하는 요일 시리즈를 만들어주세요.**

```{python eval=F}
>>> dateTime = pd.date_range("2020-01-01", "2020-01-30").to_series() # 날짜 생성
>>> dateTime[0].weekday() # weekday 메소드는 주어진 날짜의 요일을 반환합니다
2
```

**풀이**

날짜 데이터가 생소하겠지만 크게 신경쓸 필요는 없습니다. `weekday` 메소드가 요일을 반환한다는 사실을 알고 있으므로, 먼저 날짜 데이터를 받아서 요일을 반환하는 람다 함수를 짭니다. 람다를 사용해서 메소드를 함수화하였으므로 이제 `apply`와 함께 사용할 수 있습니다. 

```{python eval=F}
>>> lambda x: x.weekday()
```

`dateTime` 시리즈의 `apply` 메소드에 만들어둔 람다 함수를 넣어서 실행합니다.

```{python eval=F}
>>> dateTime.apply(lambda x: x.weekday()) # 출력 생략
```

:::

### 데이터프레임

데이터프레임을 만들 때에는 `pd.DataFrame` 안에 딕셔너리를 넣어줍니다. 이 때 딕셔너리의 키는 컬럼의 이름어야 하고, 값은 컬럼에 실제로 들어갈 요소들이어야 합니다. 행 인덱스가 필요하다면 `index` 파라미터에 행 인덱스로 사용할 값들을 넣어주면 됩니다. 

```{python eval=F}
>>> data = {
...     'apples': [3, 2, 0, 1], 
...     'oranges': [0, 3, 7, 2]
... }
>>> purchases = pd.DataFrame(data, index=['June', 'Robert', 'Lily', 'David'])
>>> purchases
```

```{python echo=F}
data = {
    'apples': [3, 2, 0, 1], 
    'oranges': [0, 3, 7, 2]}
purchases = pd.DataFrame(data, index=['June', 'Robert', 'Lily', 'David'])
purchases
```

:::warning
**예제 2.2. 아래와 같은 데이터프레임을 만들어주세요.**

```{python echo=F}
pd.DataFrame(
    {"학점":["A","B","C","A"], "학년":[3,3,1,2]}
)
```

**풀이**

데이터프레임은 학점, 학년이라는 두 개의 컬럼으로 이루어져 있습니다. 따라서 딕셔너리의 키 값은 `"학점"`,`"학년"`이 됩니다. 학점의 값은 `["A","B","C","A"]` 이고, 학년의 값은 `[3,3,1,2]`입니다. 따라서 데이터프레임을 이루는 딕셔너리는 다음과 같이 만들어졌을 것입니다.

```{python eval=F}
>>> data = {"학점":["A","B","C","A"], "학년":[3,3,1,2]}
```


이 결과를 `pd.DataFrame`으로 감싸주면 데이터프레임이 완성됩니다.

```{python eval=F}
>>> pd.DataFrame(data)
```

:::

## 2.2. 외부 데이터 읽어오기

판다스로 데이터프레임을 직접 만들 수도 있지만, 대부분의 경우에는  `csv`, `xlsx`, `json` 등 파일로 저장된 외부 데이터를 읽어와 작업을 하게 됩니다. **앞으로 가장 많이 접하게 될 `csv` 파일을 읽어오는 함수는 `pd.read_csv` 입니다.** 가장 먼저 파일이 위치한 경로를 입력하고, `encoding` 매개변수에 파일의 인코딩을 지정해줍니다. `utf-8`이 기본 옵션이므로 `utf-8` 파일을 읽어올 때에는 따로 인코딩을 지정할 필요가 없습니다. 

```{python eval=F}
>>> data = pd.read_csv("data/dataset_for_analysis.csv", encoding="ANSI")
>>> data = data.set_index("사례번호")
>>> data # 출력 생략
```

:::warning
**예제 2.2. 아래 링크의 csv 파일을 판다스로 읽어오세요.**

https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv

**풀이**

판다스는 웹에 존재하는 파일을 즉시 읽어올 수도 있습니다.

```{python eval=F}
>>> titanic = pd.read_csv(
        "https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv"
... )
>>> titanic.head() # 출력 생략
```
:::

:::warning
### 경로와 인코딩

**절대경로 상대경로, 인코딩**이 무엇인지 아시면 이 내용은 건너뛰셔도 됩니다. 

#### 경로

.|.
---|---
![](./assets/figs/path.png)|![](./assets/figs/properties.png)

**경로는 파일이 존재하는 위치를 뜻하며 절대 경로, 상대 경로로 나누어 생각할 수 있습니다.** 절대 경로는 최상위 디렉토리인 `C:` 부터 시작하는 경로인 반면, 상대 경로는 특정 디렉토리를 기준으로 상대적으로 표현된 경로입니다. 위에서 우리가 읽어들인 `dataset_for_analysis.csv` 파일을 예로 들어 보겠습니다. 먼저 해당 파일이 존재하는 위치로 가서, 파일의 속성을 확인해봅니다. 그러면 위와 같은 화면을 확인할 수 있을 것입니다. 이 때 Location 항목에 표시되는 것이 파일이 위치한 디렉토리의 절대 경로이며, 파일의 절대 경로는 `C:\Users\Administrator\pyfords\data\dataset_for_analysis.csv` 가 됩니다.

```
# 계층적으로 표현한 디렉토리 구조
C:/
    Users/
        Administrator/
            pyfords/
                data/
                    dataset_for_analysis.csv
                    gapminder.csv
                    iris.csv
```

하지만 위의 예시 코드에서는 입력한 경로는 `C:` 부터 출발하지 않는 **상대 경로**입니다. 상대 경로를 통해서 파일을 읽어올 수 있었다는 것은 분명히 기준 경로가 존재한다는 뜻입니다. 파일의 절대 경로와 상대 경로를 비교해보면, 파이썬이 인식하는 기준 경로가 `C:\Users\Administrator\pyfords\` 임을 알 수 있습니다. 만약 주피터 노트북을 사용하고 계신다면, 현재 열려있는 노트북이 실행된 위치가 기준 디렉토리가 됩니다. 파이썬 표준 패키지인 `os`를 이용하면 현재 작업중인 기준 디렉토리를 확인할 수 있습니다.

```{python eval=F}
>>> import os
>>> os.getcwd()
'C:\Users\Administrator\pyfords'
```

#### 인코딩

컴퓨터는 숫자만을 저장할 수 있습니다. 따라서 우리가 사용하는 문자들을 컴퓨터에 파일로 저장하기 위해서는 문자를 코드로 바꾸어주는 일종의 변환이 필요합니다. 이러한 변환 과정을 인코딩이라고 합니다. 반대로 인코딩된 자료를 해독하여 다시 사람이 이해할 수 있는 문자로 바꾸어주는 것을 디코딩이라고 합니다. 

문제는 인코딩에 하나의 통일된 체계가 존재하지 않는다는 점입니다. 예를 들어 `euc-kr`이라는 규칙으로 인코딩된 파일을 `utf-8`이라는 규칙으로 디코딩하려고 한다면 어떻게 될까요? 당연히 정상적으로 해독이 되지 않을 것입니다. 흔히 말해 '글자가 깨지는' 현상이 나타나거나, 혹은 아예 파일을 읽어오지 못할 것입니다. 이러한 경우에는 컴퓨터가 파일의 인코딩 규칙에 맞게 디코딩을 할 수 있도록, 파일이 어떠한 규칙으로 인코딩되었는지 알려주어야 합니다.
:::

# 3. 데이터프레임 조작

이제 본격적으로 판다스 데이터프레임을 조작하는 방법을 배워보도록 하겠습니다. 크게 아래와 같은 기능들을 학습할 것입니다.

- 변수 선택: 데이터프레임의 특정 칼럼을 추출
- 필터링: 특정 기준을 만족하는 행을 추출
- 정렬: 행을 다시 정렬
- 변수 추가: 새로운 변수를 추가
- 변수 요약: 변수를 값(스칼라)으로 요약
- 그룹별로 조작: 데이터프레임을 범주형 변수의 수준별로 묶어서 조작

## 3.1. 변수 선택

**변수를 선택한다는 것은 결국 데이터프레임에서 특정 열만을 뽑아내는 작업**입니다. 변수 선택은 다음과 같은 두 가지 방법으로 실행할 수 있습니다. 속성을 사용하는 것이 타이핑은 편하지만, 변수명에 띄어쓰기나 점`.` 등이 포함되거나 기타 속성과 겹칠 경우 사용할 수 없습니다. 대괄호와 문자열을 사용해서 열을 인덱싱하는 방법은 어떠한 경우에도 사용할 수 있습니다.

<div class="row">
  <div class="col-md-6">
**열 인덱싱**
```{python eval=F}
>>> data['명칭']
사례번호
1     노동법 개정 반대 시위
2      카탈루냐 분리독립시위
3         노란 조끼 시위
4        브렉시트 반대시위
.
.
.
Name: 명칭, dtype: object
```
  </div>
  <div class="col-md-6">
**데이터프레임의 속성**
```{python eval=F}
>>> data.명칭
사례번호
1     노동법 개정 반대 시위
2      카탈루냐 분리독립시위
3         노란 조끼 시위
4        브렉시트 반대시위
.
.
.
Name: 명칭, dtype: object
```
 </div>
</div>

### 복수 개의 열 인덱싱

**복수 개의 열을 뽑아낼 때에는 대괄호`[]` 안에 열 이름의 리스트를 넣어줍니다.** 

```{python eval=F}
>>> data[['국가','명칭', '당해 GDP 성장율']] # 대괄호 안에 리스트가 들어있습니다
         국가            명칭  당해 GDP 성장율
사례번호
1      이탈리아  노동법 개정 반대 시위    0.240000
2       스페인   카탈루냐 분리독립시위    1.370000
3       프랑스      노란 조끼 시위    1.724881
4        영국     브렉시트 반대시위    1.390000
.
.
.
```

:::warning
**예제 3.1. 판다스 데이터프레임의 `columns` 속성을 통해 데이터프레임의 컬럼 이름들에 접근할 수 있습니다. 위에서 읽어온 `titanic` 데이터의 컬럼 이름을 확인하고, 원하는 컬럼을 추출해보세요.

```{python eval=F}
>>> titanic.columns
Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',
       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],
      dtype='object')
```
:::

## 3.2. 필터링 

### 필터링의 원리: 마스킹


필터링은 특정 변수에 대해 원하는 조건을 만족하는 행을 걸러내는 조작입니다. 위에서 만들어둔 `purchases` 데이터를 예로 들어보겠습니다. `purchases` 데이터에서 사과를 1개 이상 구매한 사람들만을 걸러내려고 합니다. 이를 위해 먼저 **각 행들에 대해서 `apples` 컬럼의 값이 0보다 큰지를 판단합니다. 이 결과는 `[True, True, False, True]` 입니다. 이 결과를 행에 덮어씌워서, `True`만을 남기고 `False`는 떨어뜨립니다.**

<div class="row">
  <div class="col-md-4">

**purchases 데이터프레임**

Index|apples|oranges
---|---|---
June|3|0
Robert|2|3
Lily|0|7
David|1|2
  </div>
  <div class="col-md-6">

**마스킹: 사과를 샀는가?**

Index|apples|oranges|사과를 샀는가?
---|---|---|---
June|3|0|True
Robert|2|3|True
~~Lily~~|~~0~~|~~7~~|~~False~~
David|1|2|True
  </div>
</div>

위 과정을 판다스로 구현해보겠습니다. 먼저 사과 구매에 해당하는 변수인 `apples`를 선택해야 합니다. 다음으로 `purchases.apples` 에 대해서, 각각의 값이 `0` 보다 큰지를 판단해주면 됩니다. 연산을 실행한 결과는 `[True, True, False, True]` 의 불리언 시리즈입니다. 이러한 연산이 가능한 것은 넘파이의 브로드캐스팅 때문입니다.

<div class="row">
  <div class="col-md-6">
**1. 변수 선택**
```{python eval=F}
>>> purchases.apples
June      3
Robert    2
Lily      0
David     1
Name: apples, dtype: int64
```
  </div>
  <div class="col-md-6">
**2. 조건 판단: 브로드캐스팅**
```{python eval=F}
>>> purchases.apples > 0
June       True
Robert     True
Lily      False
David      True
Name: apples, dtype: bool
```
 </div>
</div>


<div class="row">
  <div class="col-md-6">
**3. 마스킹**
```{python eval=F}
>>> purchases[purchases.apples > 0]
        apples  oranges
June         3        0
Robert       2        3
David        1        2
```

  </div>
  <div class="col-md-6">
$$ Numpy \space Broadcasting: 
\begin{pmatrix}
3 > 0\\
2 > 0\\
0 > 0\\
1 > 0\\
\end{pmatrix}
=
\begin{pmatrix}
True\\
True\\
False\\
True\\
\end{pmatrix}
$$
  </div>
</div>

이제 이 결과를 통해 행을 인덱싱해주면 끝입니다. 데이터프레임 옆에 대괄호`[]`를 적고, 대괄호 안에 완성된 불리언 시리즈를 넣어주면, 조건이 `True`인 행들만 추출됩니다. 데이터 프레임 위에 `True`, `False`로 된 시리즈를 덧붙여서 `True`만 남긴다고 생각하시면 됩니다.

:::warning
**예제 3.2. 타이타닉 데이터에서 성별이 여성인 데이터만 골라낸 후, 생존 여부 변수를 선택하세요.**

**풀이**

타이타닉 데이터에서 성별과 생존 여부를 나타내는 컬럼은 `Sex`와 `Survived` 입니다. `titanic.Sex=='female'` 이라는 조건을 걸어서 데이터프레임을 필터링해주고, 필터링된 데이터에서 `Survived` 변수를 선택해주면 끝입니다.

```{python eval=F}
>>> titanic[titanic.Sex=='female'].Survived
1      1
2      1
3      1
8      1
9      1
      ..
880    1
882    0
885    0
887    1
888    0
Name: Survived, Length: 314, dtype: int64
```
:::

### 다중 조건으로 필터링

다중 조건을 걸 때에도, 문제는 결국 하나의 불리언 시리즈를 만들어내는 것입니다. `&`, `|` 의 논리 연산을 적절하게 활용하면 어렵지 않게 다중 조건 필터링을 구현할 수 있습니다. `purchases` 데이터의 예시를 다시 보겠습니다. 이번에는 사과와 오렌지를 모두 구매한 사람들을 골라내려고 합니다. 사과와 오렌지에 대해서 각각 0보다 큰지를 판단합니다. 이후 두 개의 조건을 연결해주면 됩니다. 우리의 관심은 **"사과와 오렌지를 모두 샀는가?"** 이므로 논리연산으로는 `&`에 해당합니다. 

**purchases 데이터프레임**

Index|apples|oranges|사과를 샀는가?|오렌지를 샀는가?|사과와 오렌지를 모두 샀는가?
---|---|---|---|---|---
~~June~~|~~3~~|~~0~~|~~True~~|~~False~~|~~False~~
Robert|2|3|True|True|True
~~Lily~~|~~0~~|~~7~~|~~False~~|~~True~~|~~False~~
David|1|2|True|True|True

위와 같은 조작을 판다스로 구현해보겠습니다. 먼저 `apples` 와 `oranges`에 대해서 각각 0보다 큰지를 판단합니다. 이 두 개의 조건은 `&` 연산으로 묶어주고, 마찬가지로 대괄호 안에 넣어서 마스킹해주면 끝입니다. 역시 넘파이의 연산 특성으로 인해서 같은 위치에 있는 요소들끼리 `&` 연산이 실행됩니다.

<div class="row">
  <div class="col-md-6">
**1. 사과를 샀는가?**
```{python eval=F}
>>> purchases.apples > 0
June       True
Robert     True
Lily      False
David      True
Name: apples, dtype: bool
```
  </div>
  <div class="col-md-6">
**2. 오렌지를 샀는가?**
```{python eval=F}
>>> purchases.oranges > 0
June      False
Robert     True
Lily       True
David      True
Name: oranges, dtype: bool
```
  </div>
</div>

<div class="row">
  <div class="col-md-7">
**3. 사과와 오렌지를 샀는가?**
```{python eval=F}
>>> (purchases.apples > 0) & (purchases.oranges > 0)
June      False
Robert     True
Lily      False
David      True
Name: apples, dtype: bool
```
  </div>
  <div class="col-md-5">
$$
\begin{pmatrix}
True \space and \space False \\
True \space and \space True \\
False \space and \space True \\
True \space and \space True
\end{pmatrix}
=
\begin{pmatrix}
False \\
True \\
False \\
True
\end{pmatrix}
$$
  </div>
</div>

**4. 마스킹**
```{python eval=F}
>>> purchases[(purchases.apples > 0) & (purchases.oranges > 0)]
        apples  oranges
Robert       2        3
David        1        2
```

:::warning
**예제 3.3. 타이타닉 데이터에서 30세 이상 남성이거나 30세 이하 여성인 행들을 골라내세요.**

**풀이**

주어진 조건을 논리연산자, 비교연산자를 사용해서 표현하면 다음과 같습니다. 

1. (30세 이상 남성) or (30세 이하 여성)
2. (30세 이상 and 남성) or (30세 이하 and 여성)
3. {(나이 >= 30) and (성별 == 남성)} or {(나이 <= 30) and (성별 == 여성)}

이 결과를 코드 한 줄로 적으면 너무 길어지므로, 두 개의 조건으로 분해해서 적어보겠습니다. `cond1` 은 30세 이상 남성에 해당하는 조건이고, `cond2`는 30세 이하 여성에 해당하는 조건입니다. 두 개의 조건을 `|` 으로 묶어주고 마스킹해주면 끝입니다. 

```{python eval=F}
>>> cond1 = (titanic.Age >= 30) & (titanic.Sex == "male")
>>> cond2 = (titanic.Age <= 30) & (titanic.Sex == "female")
>>> cond1 | cond2
0      False
1      False
2       True
3      False
4       True
       ...
Length: 891, dtype: bool
>>> titanic[cond1 | cond2]
     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked
2              3         1       3  ...   7.9250   NaN         S
4              5         0       3  ...   8.0500   NaN         S
6              7         0       1  ...  51.8625   E46         S
8              9         1       3  ...  11.1333   NaN         S
9             10         1       2  ...  30.0708   NaN         C
..           ...       ...     ...  ...      ...   ...       ...
[374 rows x 12 columns]
```
:::

## 3.3. 정렬

`sort_values` 메소드는 시리즈나 데이터프레임을 크기 순으로 정렬합니다. 시리즈는 건너뛰고, 데이터프레임 정렬에 대해서만 다루도록 하겠습니다. `sort_values(컬럼)` 과 같이 적으면 주어진 컬럼의 오름차순으로 데이터프레임을 정렬합니다. `ascending=False`를 전달하면 내림차순으로 정렬합니다.

```{python eval=F}
>>> purchases.sort_values("apples")
        apples  oranges
Lily         0        7
David        1        2
Robert       2        3
June         3        0
>>> purchases.sort_values("apples", ascending=False)
        apples  oranges
June         3        0
Robert       2        3
David        1        2
Lily         0        7
```

:::warning
**예제 3.4. 타이타닉 데이터에서 나이가 30세 이상인 행들만을 걸러내고 나이 역순으로 정렬해주세요.**

**풀이**
```{python eval=F}
>>> titanic[titanic.Age >= 30].sort_values("Age")
     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked
606          607         0       3  ...   7.8958   NaN         S
178          179         0       2  ...  13.0000   NaN         S
157          158         0       3  ...   8.0500   NaN         S
520          521         1       1  ...  93.5000   B73         S
286          287         1       3  ...   9.5000   NaN         S

[330 rows x 12 columns]
```
:::

## 3.4. 변수 추가

`assign` 메소드는 데이터프레임에 새로운 컬럼을 추가합니다. 다른 컬럼들의 정보를 반영하여 새로운 컬럼을 추가하거나, 기존에 가지고 있던 컬럼을 변형하는 경우에 사용할 수 있습니다. 예를 들어 `purchaes` 데이터프레임에서 총 과일 구매 개수를 새로운 열로 추가하려고 한다면, 다음과 같이 쓸 수 있습니다. **새롭게 추가하고자 하는 컬럼의 이름은 문자열이 아니라 변수처럼 써주어야 합니다!** `assign` 메소드는 데이터프레임 직접 변경시키지 않으므로, 결과를 저장하려면 다시 할당을 해주어야 합니다.

```{python eval=F}
>>> 데이터프레임.assign(새변수명 = 데이터)
>>> purchases.assign(total = purchases.apples + purchases.oranges)
        apples  oranges  total
June         3        0      3
Robert       2        3      5
Lily         0        7      7
David        1        2      3
```

:::warning
**예제 3.4. 사과가 하나에 500원, 오렌지가 하나에 300원이라고 가정합니다. 고객별로 얼마의 매출이 발생했는지는 나타내는 컬럼을 데이터프레임에 추가해주세요.**

```{python echo=F}
purchases.assign(amount = purchases.apples * 500 + purchases.oranges * 300)
```

**풀이**

위에서 다루었던 예시 코드에 간단한 곱하기 연산을 추가해주면 됩니다. 사과는 500원이므로 500을 곱해주고, 오렌지는 300원이므로 300을 곱해줍니다.

```{python eval=F}
>>> purchases.assign(amount = purchases.apples * 500 + purchases.oranges * 300)
```
:::

## 3.5. 변수 요약

사람은 평균, 표준편차, 중위수 등의 요약된 통계량을 통해서 데이터를 더 잘 이해할 수 있습니다. 판다스 시리즈와 데이터프레임은 데이터를 요약하는 다양한 메소드를 제공합니다. 메소드이므로 꼭 `()`와 함께 사용합니다.

메소드|시리즈|데이터프레임 
---|---|---
mean|시리즈의 평균을 반환|모든 숫자 컬럼의 평균을 반환
std|시리즈의 표준편차를 반환|모든 숫자 컬럼의 평균을 반환
median|시리즈의 중위수를 반환|모든 숫자 컬럼의 중위수를 반환
min|시리즈의 최소값을 반환|모든 숫자 컬럼의 최소값을 반환
max|시리즈의 최대값을 반환|모든 숫자 컬럼의 최대값을 반환
describe|관측값 수, 평균,표준편차, 각 분위수 반환|관측값 수, 평균,표준편차, 각 분위수 반환

<div class="row">
  <div class="col-md-6">
**시리즈**
```{python eval=F}
>>> purchases.apples.mean()
1.5
>>> purchases.apples.std()
1.2909944487358056
>>> purchases.apples.median()
1.5
>>> purchases.apples.min()
0
>>> purchases.apples.max()
3
```
  </div>
  <div class="col-md-6">
**데이터프레임**
```{python eval=F}
>>> purchases.describe()
         apples  oranges
count  4.000000  4.00000
mean   1.500000  3.00000
std    1.290994  2.94392
min    0.000000  0.00000
25%    0.750000  1.50000
50%    1.500000  2.50000
75%    2.250000  4.00000
max    3.000000  7.00000
```
  </div>
</div>

## 3.6. 그룹별 조작

### groupby 기초

![](https://jakevdp.github.io/figures/split-apply-combine.svg)

`groupby` 메소드는 말 그대로 데이터를 그룹별로 나누어 조작할 수 있도록 만들어주며, 데이터가 범주형 변수를 포함할 때 유용합니다. 위 그림은 A, B, C 그룹을 구분하고 그룹별로 데이터의 합을 집계하는 과정을 나타냅니다. 위 그림에서 나타난 조작을 판다스로 구현해보겠습니다.

```{python eval=F}
>>> data = pd.DataFrame(
...     {"key":["A","B","C","A","B","C"], "data":[1,2,3,4,5,6]}
... )
>>> data
  key  data
0   A     1
1   B     2
2   C     3
3   A     4
4   B     5
5   C     6
```
`groupby` 메소드의 괄호 안에 그룹으로 나누어줄 컬럼명을 전달합니다. `groupby` 메소드만를 실행하면 `DataFrameGroupBy` 객체가 반환됩니다. 값을 명시적으로 보여주지는 않지만, 그룹별로 쪼개진 상태라고 상상해주시면 됩니다. 이 상태에서 `sum` 메소드를 사용하면 합계를 구할 수 있습니다. `sum` 뿐만 아니라 위에서 다루었던 데이터 요약 메소드들을 모두 적용할 수 있습니다.

```{python eval=F}
>>> data.groupby("key") # 쪼개진 상태 !
<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001E001E1F608>
>>> data.groupby("key").sum() # 집계 메소드 적용
     data
key
A       5
B       7
C       9
```

### 변수 선택

`DataFrameGroupBy` 객체에서도 변수를 선택할 수 있으며, 데이터프레임에서 하던 것과 동일합니다. 먼저 `purchases` 데이터에 결혼 여부 컬럼을 추가하고, 결혼 여부에 따라 사과, 오렌지의 평균 구매 개수를 계산해봅니다.

**데이터프레임에 변수 추가**
```{python eval=F}
>>> purchases = purchases.assign(married = [0,1,1,0])
>>> purchases.groupby("married").mean()
         apples  oranges
married
0             2        1
1             1        5 
```


만약 우리가 사과에는 관심이 없고, 오렌지에만 관심이 있다면 어떨까요? 먼저 평균을 집계한 이후, 그 결과에서 `oranges`만을 뽑아낼 수 있습니다. 하지만 이러한 코드는 데이터가 커진다면 시간을 상당히 낭비하는 코드일 수 있습니다. 이런 경우에는 먼저 변수를 선택한 후에 집계를 하는 편이 효율적입니다.

<div class="row">
  <div class="col-md-6">
**집계 후 변수 선택**
```{python eval=F}
>>> purchases.groupby("married").mean().oranges
married
0    1
1    5
Name: oranges, dtype: int64
```
  </div>
  <div vlass="col-md-6">
**변수 선택 후 집계: 계산 절약**
```{python eval=F}
>>> purchases.groupby("married").oranges.mean()
married
0    1
1    5
Name: oranges, dtype: int64
```
 </div>
</div>

### 여러 변수로 그루핑

여러 변수를 통해 그룹을 분리하는 것도 가능합니다. `groupby` 메소드에 변수들의 리스트를 전달해주면 됩니다. `purchases` 데이터에 새로운 컬럼을 추가해보겠습니다.

```{python eval=F}
>>> purchases = purchases.assign(graduate = [True, True, True, False])
>>> purchases.groupby(["married","graduate"]).mean()
                  apples  oranges
married graduate
0       False          1        2
        True           3        0
1       True           1        5
```

:::warning
**예제 3.5. 타이타닉 데이터에서 선실 등급별/성별 생존률을 계산하세요. 선실 등급을 나타내는 변수는 `Pclass` 입니다.**


```
Pclass  Sex
1       female    0.968085
        male      0.368852
2       female    0.921053
        male      0.157407
3       female    0.500000
        male      0.135447
Name: Survived, dtype: float64
```

**풀이**

`groupby` 메소드에 그룹지을 변수들의 리스트, 즉 `['Pclass','Sex']`을 전달해줍니다. 생존 여부가 0과 1로 코딩되어 있으므로 평균을 통해서 각 그룹의 생존률을 계산할 수 있습니다. 따라서 그룹바이 객체에서 `Survived` 변수를 선택하고, 평균을 구해줍니다.

```{python eval=F}
>>> titanic.groupby(["Pclass","Sex"]).Survived.mean()
```
:::

# 4. 복수의 데이터프레임 조작: merge & concat

